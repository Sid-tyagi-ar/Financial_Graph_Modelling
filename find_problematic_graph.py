
import hydra
from omegaconf import DictConfig, OmegaConf
import torch
import os
from hydra.utils import get_original_cwd

# Add the project root to the Python path to allow imports from src
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.datasets.transaction_dataset import TransactionDataModule
from src import utils

def find_problematic_batch(cfg: DictConfig):
    """
    Iterates through the dataset to find a batch that causes the size mismatch.
    """
    # Manually load and merge the experiment and dataset configs
    exp_config = OmegaConf.load(os.path.join(get_original_cwd(), "configs/experiment/test.yaml"))
    data_config = OmegaConf.load(os.path.join(get_original_cwd(), "configs/dataset/transaction.yaml"))
    cfg = OmegaConf.merge(cfg, exp_config)
    cfg.dataset = OmegaConf.merge(cfg.dataset, data_config)

    print("--- Initializing DataModule ---")
    datamodule = TransactionDataModule(cfg)
    
    print("--- Iterating through training dataloader ---")
    for i, batch in enumerate(datamodule.train_dataloader()):
        print(f"Checking batch {i}...", end='\r')

        # --- Mimic logic from training_step and TrainLossDiscrete.forward ---
        dense_data, node_mask = utils.to_dense(batch.x, batch.edge_index, batch.edge_attr, batch.batch)
        dense_data = dense_data.mask(node_mask)
        true_X = dense_data.X

        # The prediction tensor would be generated by the model
        # For this check, we only care about its shape, which should match true_X
        pred_X = torch.randn_like(true_X)

        # Reshape
        true_X_reshaped = torch.reshape(true_X, (-1, true_X.size(-1)))
        pred_X_reshaped = torch.reshape(pred_X, (-1, pred_X.size(-1)))

        # Create mask based on ground truth
        mask_X = (true_X_reshaped != 0.).any(dim=-1)

        # Apply mask
        flat_true_X = true_X_reshaped[mask_X, :]
        flat_pred_X = pred_X_reshaped[mask_X, :]

        # THE ERROR CONDITION CHECK
        if flat_pred_X.size(0) > 0 and flat_true_X.size(0) == 0:
            print(f"\n\n--- !!! Problematic Batch Found: Batch {i} !!! ---")
            print(f"Original batch size: {batch.num_graphs}")
            print(f"Total nodes in batch (incl. padding): {true_X.shape[1]}")
            print(f"Shape of true_X before reshape: {true_X.shape}")
            print(f"Shape of true_X after reshape: {true_X_reshaped.shape}")
            print(f"Number of active rows in mask_X: {mask_X.sum()}")
            print(f"Shape of flat_true_X (masked): {flat_true_X.shape}")
            print(f"Shape of flat_pred_X (masked): {flat_pred_X.shape}")
            print("\nThis batch results in an empty `flat_true_X` but a non-empty `flat_pred_X`,")
            print("which is impossible if they are sliced with the same mask.")
            print("This indicates a deeper issue.")
            return

        # Check the specific error from the log
        if flat_pred_X.size(0) > 0 and flat_true_X.numel() == 0:
             # This is the condition that would cause the error inside the loop
             # if true_slice.numel() == 0, but pred_slice is not empty.
             # This is also impossible if they have the same number of rows.
             pass


    print("\n--- Search Complete ---")
    print("No problematic batch found that matches the error description.")
    print("This suggests the error is not due to a specific data batch's structure,")
    print("but might be a more subtle bug related to the model's output or the masking process.")

@hydra.main(config_path="configs", config_name="config", version_base="1.1")
def main(cfg: DictConfig):
    find_problematic_batch(cfg)

if __name__ == "__main__":
    main()
